name: e2e

on:
  workflow_dispatch:
  push:
    branches:
      - master
  pull_request:
    branches:
      - master

jobs:
  kubernetes:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Create a kubernetes cluster
        uses: debianmaster/actions-k3s@master
        with:
          version: 'latest'

      - name: Start the testpv app, which will write to a new PersistentVolume (PV)
        run: |
          kubectl apply -k .github/testpv
          echo "Waiting for the app to be ready..."
          while ! kubectl wait --timeout=5m --for=condition=ready pod -l app=testpv -n testpv; do
            sleep 1 # Wait for the pod to exist if wait fails
          done

      - name: Force a backup of the PV now
        run: |
          kubectl create job --from=cronjob/k8s-simple-backup-cron-job -n testpv k8s-simple-backup-job
          kubectl wait --timeout=5m --for=condition=complete -n testpv job/k8s-simple-backup-job
          kubectl logs -f --all-containers=true --timestamps -n testpv job/k8s-simple-backup-job \
            | sort | sed -E 's/^[^T]+T//g;s/(:[0-9]{2}\.[0-9]{1})[^ ]+/\1/g' | tee logs.txt
          saved_snapshot=$(grep "Archive name: " logs.txt | sed -E 's/.*Archive name: //g' | head -n 1)
          if [ -z "$saved_snapshot" ]; then
            echo "ERROR: No snapshot was found in the logs:"
            cat logs.txt
            exit 1
          fi
          rm logs.txt && echo "saved_snapshot=$saved_snapshot" | tee /dev/stderr >> $GITHUB_ENV
          kubectl delete job -n testpv k8s-simple-backup-job

      - name: Let the app run for a bit and print the logs
        run: |
          sleep 10
          kubectl logs -n testpv -l app=testpv --tail 100 | tee future_logs.txt

      - name: Force a restore of the PV now (to the backup we just made)
        run: |
          kubectl create job -n testpv --from=cronjob/k8s-simple-backup-cron-job k8s-simple-backup-job-restore --dry-run=client -o "json" \
            | jq ".spec.template.spec.initContainers[1].env += [{ \"name\": \"ARCHIVE\", value:\"$saved_snapshot\" }, { \"name\": \"EXTRACT_TO\", value:\"/\" }, { \"name\": \"DEBUG\", value:\"1\" }]" \
            | kubectl apply -f -
          kubectl wait --timeout=5m --for=condition=complete -n testpv job/k8s-simple-backup-job-restore
          kubectl logs -f --all-containers=true --timestamps -n testpv job/k8s-simple-backup-job-restore \
            | sort | sed -E 's/^[^T]+T//g;s/(:[0-9]{2}\.[0-9]{1})[^ ]+/\1/g'
          kubectl delete job -n testpv k8s-simple-backup-job-restore

      - name: Let the app run for a bit and print the logs (should have gone back to the past!)
        run: |
          sleep 10
          kubectl logs -n testpv -l app=testpv --tail 100 | tee past_logs.txt
          # Ensure that the past logs partially match the future logs
          grep -q -f future_logs.txt past_logs.txt

      - name: Debug information
        if: always()
        run: |
          echo " ======== Get all resources in all namespaces ======== "
          kubectl api-resources --verbs=list --namespaced -o name \
          | xargs -I {} sh -c 'echo "     === {} in all namespaces === "; kubectl get --ignore-not-found --all-namespaces {}'
          
          echo " ======== Describe all resources in all namespaces ======== "
          resource_kinds=$(kubectl api-resources --verbs=list --namespaced -o name)
          for resource_kind in $resource_kinds; do
            echo "     === $resource_kind in all namespaces === "
            resources=$(kubectl get --ignore-not-found --all-namespaces $resource_kind -o custom-columns='N:.metadata.name,NS:.metadata.namespace' | sed -E '1d')
            while read -r resource; do
              if [ -z "$resource" ]; then
                continue
              fi
              name=$(echo $resource | sed -E 's/ +/ /g' | cut -d' ' -f1)
              namespace=$(echo $resource | sed -E 's/ +/ /g' | cut -d' ' -f2)
              echo -e "\n       = Describe $resource_kind/$name in namespace $namespace = "
              kubectl describe -n $namespace $resource_kind/$name
            done <<< "$resources"
          done
          
          for resource_kind_with_logs in "pods"; do
            echo " ======== Logs for all $resource_kind_with_logs in all namespaces ======== "
            all_resources=$(kubectl get $resource_kind_with_logs --all-namespaces -o custom-columns='N:.metadata.name,NS:.metadata.namespace' | tail -n +2)
            readarray -t all_resources <<< "$all_resources"
            for resource in "${all_resources[@]}"; do
              resource=($resource)
              echo " ========== Previous logs for $resource_kind_with_logs ${resource[0]} in namespace ${resource[1]} ========== "
              kubectl -n "${resource[1]}" logs "${resource[0]}" --previous --all-containers=true --tail=-1 --timestamps \
                | sort | sed -E 's/^[^T]+T//g;s/(:[0-9]{2}\.[0-9]{1})[^ ]+/\1/g' || \
                echo "Failed to get PREVIOUS logs for $resource_kind_with_logs ${resource[0]} in namespace ${resource[1]}"
              echo " ========== Logs for $resource_kind_with_logs ${resource[0]} in namespace ${resource[1]} ========== "
              kubectl -n "${resource[1]}" logs "${resource[0]}" --all-containers=true --tail=-1 --timestamps \
                | sort | sed -E 's/^[^T]+T//g;s/(:[0-9]{2}\.[0-9]{1})[^ ]+/\1/g' || \
                echo "Failed to get logs for $resource_kind_with_logs ${resource[0]} in namespace ${resource[1]}"
            done
          done



